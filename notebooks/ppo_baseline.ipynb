{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A naive approach: let's try PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tianshou as ts \n",
    "from tianshou.utils import TensorboardLogger\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from utils import ResettingEnvironment\n",
    "from networks import SimpleNetHackActor, SimpleNetHackCritic\n",
    "\n",
    "from nle.env.tasks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ResettingEnvironment(NetHackGold())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_envs = 5\n",
    "num_test_envs = 5\n",
    "\n",
    "train_envs = ts.env.DummyVectorEnv([lambda: env for _ in range(num_train_envs)])\n",
    "test_envs = ts.env.DummyVectorEnv([lambda: env for _ in range(num_test_envs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_net = SimpleNetHackActor(env.observation_space, env.action_space)\n",
    "critic_net = SimpleNetHackCritic(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a single optimizer for actor and critic simplifies the training loop and is more computationally efficient\n",
    "# BUT gradient updates in one network will influence the gradient updates in the other, and this might create unexpected problems...\n",
    "combined_params = list(actor_net.parameters()) + list(critic_net.parameters())\n",
    "optimizer = torch.optim.Adam(combined_params, lr=3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_fn(logits: torch.Tensor):\n",
    "    return torch.distributions.Categorical(logits=logits)\n",
    "\n",
    "policy = ts.policy.PPOPolicy(\n",
    "    actor=actor_net, \n",
    "    critic=critic_net, \n",
    "    optim=optimizer,\n",
    "    dist_fn=dist_fn,\n",
    "    action_space=env.action_space,\n",
    "    action_scaling=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_collector = ts.data.Collector(policy, train_envs, ts.data.VectorReplayBuffer(2000, num_train_envs))\n",
    "\n",
    "test_collector = ts.data.Collector(policy, test_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_steps_per_epoch = 1000\n",
    "\n",
    "step_per_collect = 10\n",
    "episode_per_test = 6\n",
    "batch_size = 10\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%d%m%Y-%H%M%S\")\n",
    "log_path = os.path.join(\"logs\", \"ppo\", timestamp)\n",
    "writer = SummaryWriter(log_path)\n",
    "logger = TensorboardLogger(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ts.trainer.OnpolicyTrainer(\n",
    "    policy=policy, \n",
    "    train_collector=train_collector, \n",
    "    test_collector=test_collector,\n",
    "    repeat_per_collect=1,\n",
    "    max_epoch=num_epochs,\n",
    "    step_per_epoch=num_steps_per_epoch,\n",
    "    step_per_collect=step_per_collect,\n",
    "    episode_per_test=episode_per_test,\n",
    "    batch_size=batch_size,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1001it [00:12, 78.86it/s, env_step=1000, gradient_step=300, len=523, n/ep=0, n/st=10, rew=-1.73]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: -2.983333 ± 2.134359, best_reward: -2.363333 ± 2.438399 in #0\n",
      "Epoch: EpochStats(epoch=1, train_collect_stat=CollectStats(n_collected_episodes=0, n_collected_steps=10, collect_time=0.020969867706298828, collect_speed=476.8747299724856, returns=array([], dtype=float64), returns_stat=None, lens=array([], dtype=int64), lens_stat=None), test_collect_stat=CollectStats(n_collected_episodes=6, n_collected_steps=7153, collect_time=20.25036096572876, collect_speed=353.2282714419546, returns=array([-0.6 , -1.44, -2.08, -2.53, -4.16, -7.09]), returns_stat=SequenceSummaryStats(mean=-2.983333333333307, std=2.1343591283775853, max=-0.6000000000000003, min=-7.089999999999893), lens=array([ 258,  537,  833, 1031, 1581, 2913]), lens_stat=SequenceSummaryStats(mean=1192.1666666666667, std=872.6726031119703, max=2913.0, min=258.0)), training_stat=PPOTrainingStats(train_time=0.10072898864746094, smoothed_loss={'loss': 3.236992934944283e-05, 'clip_loss': 1.117121399829557e-09, 'vf_loss': 6.473772912613641e-05, 'ent_loss': 5.199288117818668e-09}, loss=SequenceSummaryStats(mean=2.4082955860649236e-05, std=0.0, max=2.4082955860649236e-05, min=2.4082955860649236e-05), clip_loss=SequenceSummaryStats(mean=-2.9802322387695312e-08, std=0.0, max=-2.9802322387695312e-08, min=-2.9802322387695312e-08), vf_loss=SequenceSummaryStats(mean=4.8225549107883126e-05, std=0.0, max=4.8225549107883126e-05, min=4.8225549107883126e-05), ent_loss=SequenceSummaryStats(mean=1.5590326807313204e-09, std=0.0, max=1.5590326807313204e-09, min=1.5590326807313204e-09)), info_stat=InfoStats(gradient_step=300, best_reward=-2.36333333333331, best_reward_std=2.4383988371242102, train_step=1000, train_episode=1, test_step=12797, test_episode=12, timing=TimingStats(total_time=52.339439153671265, train_time=12.802882194519043, train_time_collect=2.22943115234375, train_time_update=30.67535924911499, test_time=39.53655695915222, update_speed=78.10741244093485)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1001it [00:12, 78.33it/s, env_step=2000, gradient_step=400, len=523, n/ep=0, n/st=10, rew=-1.73]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: -2.648333 ± 2.292105, best_reward: -2.363333 ± 2.438399 in #0\n",
      "Epoch: EpochStats(epoch=2, train_collect_stat=CollectStats(n_collected_episodes=0, n_collected_steps=10, collect_time=0.021883249282836914, collect_speed=456.9705289535327, returns=array([], dtype=float64), returns_stat=None, lens=array([], dtype=int64), lens_stat=None), test_collect_stat=CollectStats(n_collected_episodes=6, n_collected_steps=6400, collect_time=19.48100209236145, collect_speed=328.52519442567365, returns=array([-0.56, -1.32, -1.92, -1.3 , -3.4 , -7.39]), returns_stat=SequenceSummaryStats(mean=-2.6483333333333103, std=2.2921054125458618, max=-0.5600000000000003, min=-7.389999999999887), lens=array([ 274,  553,  765,  510, 1459, 2839]), lens_stat=SequenceSummaryStats(mean=1066.6666666666667, std=874.4660593121318, max=2839.0, min=274.0)), training_stat=PPOTrainingStats(train_time=0.10609817504882812, smoothed_loss={'loss': 1.4486352015410375e-05, 'clip_loss': -5.55068220275956e-10, 'vf_loss': 2.8973886765015776e-05, 'ent_loss': 3.6265689254411092e-09}, loss=SequenceSummaryStats(mean=1.0926789400400594e-05, std=0.0, max=1.0926789400400594e-05, min=1.0926789400400594e-05), clip_loss=SequenceSummaryStats(mean=-1.1920929132713809e-08, std=0.0, max=-1.1920929132713809e-08, min=-1.1920929132713809e-08), vf_loss=SequenceSummaryStats(mean=2.1877425751881674e-05, std=0.0, max=2.1877425751881674e-05, min=2.1877425751881674e-05), ent_loss=SequenceSummaryStats(mean=2.706670998442462e-10, std=0.0, max=2.706670998442462e-10, min=2.706670998442462e-10)), info_stat=InfoStats(gradient_step=400, best_reward=-2.36333333333331, best_reward_std=2.4383988371242102, train_step=2000, train_episode=1, test_step=19197, test_episode=18, timing=TimingStats(total_time=84.633798122406, train_time=25.616239070892334, train_time_collect=4.462653398513794, train_time_update=41.076580286026, test_time=59.01755905151367, update_speed=78.07547370498251)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1001it [00:12, 79.26it/s, env_step=3000, gradient_step=500, len=523, n/ep=0, n/st=10, rew=-1.73]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: -2.711667 ± 2.068860, best_reward: -2.363333 ± 2.438399 in #0\n",
      "Epoch: EpochStats(epoch=3, train_collect_stat=CollectStats(n_collected_episodes=0, n_collected_steps=10, collect_time=0.021863222122192383, collect_speed=457.3891233465284, returns=array([], dtype=float64), returns_stat=None, lens=array([], dtype=int64), lens_stat=None), test_collect_stat=CollectStats(n_collected_episodes=6, n_collected_steps=6465, collect_time=19.63693904876709, collect_speed=329.2264636532498, returns=array([-0.61, -0.99, -1.  , -2.92, -4.62, -6.13]), returns_stat=SequenceSummaryStats(mean=-2.7116666666666407, std=2.0688597235084405, max=-0.6100000000000003, min=-6.129999999999914), lens=array([ 283,  365,  418, 1151, 1721, 2527]), lens_stat=SequenceSummaryStats(mean=1077.5, std=826.0721820761186, max=2527.0, min=283.0)), training_stat=PPOTrainingStats(train_time=0.10517597198486328, smoothed_loss={'loss': 1.427446832167334e-05, 'clip_loss': -2.499669899957979e-09, 'vf_loss': 2.855398030987999e-05, 'ent_loss': 2.210192193430327e-09}, loss=SequenceSummaryStats(mean=1.0680148079700302e-05, std=0.0, max=1.0680148079700302e-05, min=1.0680148079700302e-05), clip_loss=SequenceSummaryStats(mean=-1.1920929132713809e-08, std=0.0, max=-1.1920929132713809e-08, min=-1.1920929132713809e-08), vf_loss=SequenceSummaryStats(mean=2.1384141291491687e-05, std=0.0, max=2.1384141291491687e-05, min=2.1384141291491687e-05), ent_loss=SequenceSummaryStats(mean=1.7922349715426833e-10, std=0.0, max=1.7922349715426833e-10, min=1.7922349715426833e-10)), info_stat=InfoStats(gradient_step=500, best_reward=-2.36333333333331, best_reward_std=2.4383988371242102, train_step=3000, train_episode=1, test_step=25662, test_episode=24, timing=TimingStats(total_time=116.93605208396912, train_time=38.281553983688354, train_time_collect=6.651926517486572, train_time_update=51.37034893035889, test_time=78.65449810028076, update_speed=78.36672464441465)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1001it [00:13, 76.17it/s, env_step=4000, gradient_step=600, len=523, n/ep=0, n/st=10, rew=-1.73]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: -2.315000 ± 2.001564, best_reward: -2.315000 ± 2.001564 in #4\n",
      "Epoch: EpochStats(epoch=4, train_collect_stat=CollectStats(n_collected_episodes=0, n_collected_steps=10, collect_time=0.02273416519165039, collect_speed=439.8666023449462, returns=array([], dtype=float64), returns_stat=None, lens=array([], dtype=int64), lens_stat=None), test_collect_stat=CollectStats(n_collected_episodes=6, n_collected_steps=5661, collect_time=17.361329078674316, collect_speed=326.0695062196393, returns=array([-0.02, -0.66, -1.12, -2.26, -4.18, -5.65]), returns_stat=SequenceSummaryStats(mean=-2.3149999999999795, std=2.0015639718313327, max=-0.02, min=-5.649999999999924), lens=array([  18,  267,  539, 1001, 1701, 2135]), lens_stat=SequenceSummaryStats(mean=943.5, std=760.9870235424518, max=2135.0, min=18.0)), training_stat=PPOTrainingStats(train_time=0.10118818283081055, smoothed_loss={'loss': 1.4058788274269318e-05, 'clip_loss': 1.7695129150840927e-09, 'vf_loss': 2.8114101323808426e-05, 'ent_loss': 3.191674878555428e-09}, loss=SequenceSummaryStats(mean=1.2180335943412501e-05, std=0.0, max=1.2180335943412501e-05, min=1.2180335943412501e-05), clip_loss=SequenceSummaryStats(mean=1.7881394143159923e-08, std=0.0, max=1.7881394143159923e-08, min=1.7881394143159923e-08), vf_loss=SequenceSummaryStats(mean=2.4324914193130098e-05, std=0.0, max=2.4324914193130098e-05, min=2.4324914193130098e-05), ent_loss=SequenceSummaryStats(mean=2.4109703122832116e-10, std=0.0, max=2.4109703122832116e-10, min=2.4109703122832116e-10)), info_stat=InfoStats(gradient_step=600, best_reward=-2.3149999999999795, best_reward_std=2.0015639718313327, train_step=4000, train_episode=1, test_step=31323, test_episode=30, timing=TimingStats(total_time=147.47279715538025, train_time=51.45696997642517, train_time_collect=8.919453382492065, train_time_update=62.09424138069153, test_time=96.01582717895508, update_speed=77.73485305941227)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1001it [00:13, 72.89it/s, env_step=5000, gradient_step=700, len=523, n/ep=0, n/st=10, rew=-1.73]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: -2.535000 ± 1.931474, best_reward: -2.315000 ± 2.001564 in #4\n",
      "Epoch: EpochStats(epoch=5, train_collect_stat=CollectStats(n_collected_episodes=0, n_collected_steps=10, collect_time=0.022660017013549805, collect_speed=441.30593520827415, returns=array([], dtype=float64), returns_stat=None, lens=array([], dtype=int64), lens_stat=None), test_collect_stat=CollectStats(n_collected_episodes=6, n_collected_steps=6078, collect_time=18.988116979599, collect_speed=320.09493129467535, returns=array([-0.66, -1.44, -1.76, -1.81, -2.96, -6.58]), returns_stat=SequenceSummaryStats(mean=-2.5349999999999815, std=1.93147396220258, max=-0.6600000000000004, min=-6.579999999999904), lens=array([ 274,  553,  614,  762, 1134, 2741]), lens_stat=SequenceSummaryStats(mean=1013.0, std=814.5088499621515, max=2741.0, min=274.0)), training_stat=PPOTrainingStats(train_time=0.10525321960449219, smoothed_loss={'loss': 1.410766929438978e-05, 'clip_loss': 1.8142162561129994e-09, 'vf_loss': 2.821175439748913e-05, 'ent_loss': 2.208602839920415e-09}, loss=SequenceSummaryStats(mean=1.2872336810687557e-05, std=0.0, max=1.2872336810687557e-05, min=1.2872336810687557e-05), clip_loss=SequenceSummaryStats(mean=0.0, std=0.0, max=-0.0, min=-0.0), vf_loss=SequenceSummaryStats(mean=2.574467725935392e-05, std=0.0, max=2.574467725935392e-05, min=2.574467725935392e-05), ent_loss=SequenceSummaryStats(mean=1.6468224006693788e-10, std=0.0, max=1.6468224006693788e-10, min=1.6468224006693788e-10)), info_stat=InfoStats(gradient_step=700, best_reward=-2.3149999999999795, best_reward_std=2.0015639718313327, train_step=5000, train_episode=1, test_step=37401, test_episode=36, timing=TimingStats(total_time=180.22910118103027, train_time=65.2251570224762, train_time_collect=11.260546684265137, train_time_update=73.33327913284302, test_time=115.00394415855408, update_speed=76.6575387204822)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1001it [00:13, 74.57it/s, env_step=6000, gradient_step=800, len=523, n/ep=0, n/st=10, rew=-1.73]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: -2.428333 ± 2.337095, best_reward: -2.315000 ± 2.001564 in #4\n",
      "Epoch: EpochStats(epoch=6, train_collect_stat=CollectStats(n_collected_episodes=0, n_collected_steps=10, collect_time=0.022851228713989258, collect_speed=437.6132296937764, returns=array([], dtype=float64), returns_stat=None, lens=array([], dtype=int64), lens_stat=None), test_collect_stat=CollectStats(n_collected_episodes=6, n_collected_steps=5811, collect_time=19.133152961730957, collect_speed=303.71366452893733, returns=array([-0.06, -0.71, -1.69, -1.53, -3.49, -7.09]), returns_stat=SequenceSummaryStats(mean=-2.428333333333311, std=2.3370951818205246, max=-0.060000000000000005, min=-7.089999999999893), lens=array([  42,  313,  650,  715, 1381, 2710]), lens_stat=SequenceSummaryStats(mean=968.5, std=880.9810346047941, max=2710.0, min=42.0)), training_stat=PPOTrainingStats(train_time=0.11280608177185059, smoothed_loss={'loss': 1.3667898247149424e-05, 'clip_loss': -1.788139403213762e-10, 'vf_loss': 2.733622423875204e-05, 'ent_loss': 3.4963384010211485e-09}, loss=SequenceSummaryStats(mean=9.963636330212466e-06, std=0.0, max=9.963636330212466e-06, min=9.963636330212466e-06), clip_loss=SequenceSummaryStats(mean=-2.3841858265427618e-08, std=0.0, max=-2.3841858265427618e-08, min=-2.3841858265427618e-08), vf_loss=SequenceSummaryStats(mean=1.9974961105617695e-05, std=0.0, max=1.9974961105617695e-05, min=1.9974961105617695e-05), ent_loss=SequenceSummaryStats(mean=2.7872201768808225e-10, std=0.0, max=2.7872201768808225e-10, min=2.7872201768808225e-10)), info_stat=InfoStats(gradient_step=800, best_reward=-2.3149999999999795, best_reward_std=2.0015639718313327, train_step=6000, train_episode=1, test_step=43212, test_episode=42, timing=TimingStats(total_time=212.82070302963257, train_time=78.68360590934753, train_time_collect=13.558892726898193, train_time_update=84.30398178100586, test_time=134.13709712028503, update_speed=76.25476655089604)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1001it [00:14, 67.96it/s, env_step=7000, gradient_step=900, len=1149, n/ep=0, n/st=10, rew=-3.06]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: -2.458333 ± 2.130614, best_reward: -2.315000 ± 2.001564 in #4\n",
      "Epoch: EpochStats(epoch=7, train_collect_stat=CollectStats(n_collected_episodes=0, n_collected_steps=10, collect_time=0.024194717407226562, collect_speed=413.3133622388648, returns=array([], dtype=float64), returns_stat=None, lens=array([], dtype=int64), lens_stat=None), test_collect_stat=CollectStats(n_collected_episodes=6, n_collected_steps=5860, collect_time=19.84908103942871, collect_speed=295.2277734349288, returns=array([-0.67, -1.42, -1.61, -0.88, -3.36, -6.81]), returns_stat=SequenceSummaryStats(mean=-2.4583333333333126, std=2.130613500588207, max=-0.6700000000000004, min=-6.809999999999899), lens=array([ 245,  517,  650,  413, 1344, 2691]), lens_stat=SequenceSummaryStats(mean=976.6666666666666, std=841.1235871671231, max=2691.0, min=245.0)), training_stat=PPOTrainingStats(train_time=0.12093210220336914, smoothed_loss={'loss': 7.57765032858515e-05, 'clip_loss': -1.0672957451163256e-09, 'vf_loss': 0.00015155521770793712, 'ent_loss': 3.899378000493669e-09}, loss=SequenceSummaryStats(mean=1.17563486128347e-05, std=0.0, max=1.17563486128347e-05, min=1.17563486128347e-05), clip_loss=SequenceSummaryStats(mean=-4.7683716530855236e-08, std=0.0, max=-4.7683716530855236e-08, min=-4.7683716530855236e-08), vf_loss=SequenceSummaryStats(mean=2.3608079573023133e-05, std=0.0, max=2.3608079573023133e-05, min=2.3608079573023133e-05), ent_loss=SequenceSummaryStats(mean=6.84722778476754e-10, std=0.0, max=6.84722778476754e-10, min=6.84722778476754e-10)), info_stat=InfoStats(gradient_step=900, best_reward=-2.3149999999999795, best_reward_std=2.0015639718313327, train_step=7000, train_episode=2, test_step=49072, test_episode=48, timing=TimingStats(total_time=247.4372160434723, train_time=93.45103788375854, train_time_collect=16.019238233566284, train_time_update=96.4014663696289, test_time=153.98617815971375, update_speed=74.90553511783494)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1001it [00:13, 75.34it/s, env_step=8000, gradient_step=1000, len=1884, n/ep=0, n/st=10, rew=-5.18]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: -2.451667 ± 2.436099, best_reward: -2.315000 ± 2.001564 in #4\n",
      "Epoch: EpochStats(epoch=8, train_collect_stat=CollectStats(n_collected_episodes=0, n_collected_steps=10, collect_time=0.023846149444580078, collect_speed=419.3549161150993, returns=array([], dtype=float64), returns_stat=None, lens=array([], dtype=int64), lens_stat=None), test_collect_stat=CollectStats(n_collected_episodes=6, n_collected_steps=5616, collect_time=18.7675302028656, collect_speed=299.2402270993813, returns=array([-0.01, -0.67, -1.48, -1.76, -3.43, -7.36]), returns_stat=SequenceSummaryStats(mean=-2.4516666666666436, std=2.4360994551855555, max=-0.01, min=-7.3599999999998875), lens=array([   3,  269,  596,  654, 1368, 2726]), lens_stat=SequenceSummaryStats(mean=936.0, std=903.8091612724447, max=2726.0, min=3.0)), training_stat=PPOTrainingStats(train_time=0.10635495185852051, smoothed_loss={'loss': 4.757172201607318e-05, 'clip_loss': 1.436099410501157e-09, 'vf_loss': 9.514066794963583e-05, 'ent_loss': 4.907667584541642e-09}, loss=SequenceSummaryStats(mean=2.338114609301556e-05, std=0.0, max=2.338114609301556e-05, min=2.338114609301556e-05), clip_loss=SequenceSummaryStats(mean=1.1920929132713809e-08, std=0.0, max=1.1920929132713809e-08, min=1.1920929132713809e-08), vf_loss=SequenceSummaryStats(mean=4.673846342484467e-05, std=0.0, max=4.673846342484467e-05, min=4.673846342484467e-05), ent_loss=SequenceSummaryStats(mean=7.817168024004673e-10, std=0.0, max=7.817168024004673e-10, min=7.817168024004673e-10)), info_stat=InfoStats(gradient_step=1000, best_reward=-2.3149999999999795, best_reward_std=2.0015639718313327, train_step=8000, train_episode=3, test_step=54688, test_episode=54, timing=TimingStats(total_time=279.52684211730957, train_time=106.77313375473022, train_time_collect=18.260602474212646, train_time_update=107.2931604385376, test_time=172.75370836257935, update_speed=74.92521497380503)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1001it [00:13, 75.51it/s, env_step=9000, gradient_step=1100, len=1884, n/ep=0, n/st=10, rew=-5.18]                          \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m trainer:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch)\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/tianshou/trainer/base.py:348\u001b[0m, in \u001b[0;36mBaseTrainer.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;66;03m# test\u001b[39;00m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_collector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 348\u001b[0m         test_stat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_fn_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m info_stat \u001b[38;5;241m=\u001b[39m gather_info(\n\u001b[1;32m    351\u001b[0m     start_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_time,\n\u001b[1;32m    352\u001b[0m     policy_update_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_update_time,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     test_collector\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_collector,\n\u001b[1;32m    358\u001b[0m )\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_info_data(asdict(info_stat), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch)\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/tianshou/trainer/base.py:376\u001b[0m, in \u001b[0;36mBaseTrainer.test_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_collector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m stop_fn_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m test_stat \u001b[38;5;241m=\u001b[39m \u001b[43mtest_episode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_collector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepisode_per_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreward_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m test_stat\u001b[38;5;241m.\u001b[39mreturns_stat \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m    386\u001b[0m rew, rew_std \u001b[38;5;241m=\u001b[39m test_stat\u001b[38;5;241m.\u001b[39mreturns_stat\u001b[38;5;241m.\u001b[39mmean, test_stat\u001b[38;5;241m.\u001b[39mreturns_stat\u001b[38;5;241m.\u001b[39mstd\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/tianshou/trainer/utils.py:30\u001b[0m, in \u001b[0;36mtest_episode\u001b[0;34m(collector, test_fn, epoch, n_episode, logger, global_step, reward_metric)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_fn:\n\u001b[1;32m     29\u001b[0m     test_fn(epoch, global_step)\n\u001b[0;32m---> 30\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcollector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_episode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_episode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reward_metric:  \u001b[38;5;66;03m# TODO: move into collector\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     rew \u001b[38;5;241m=\u001b[39m reward_metric(result\u001b[38;5;241m.\u001b[39mreturns)\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/tianshou/data/collector.py:304\u001b[0m, in \u001b[0;36mBaseCollector.collect\u001b[0;34m(self, n_step, n_episode, random, render, reset_before_collect, gym_reset_kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset(reset_buffer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, gym_reset_kwargs\u001b[38;5;241m=\u001b[39mgym_reset_kwargs)\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_train_mode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_episode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_episode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgym_reset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgym_reset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/tianshou/data/collector.py:507\u001b[0m, in \u001b[0;36mCollector._collect\u001b[0;34m(self, n_step, n_episode, random, render, gym_reset_kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m last_hidden_state_RH \u001b[38;5;241m=\u001b[39m _nullable_slice(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_collect_hidden_state_RH,\n\u001b[1;32m    489\u001b[0m     ready_env_ids_R,\n\u001b[1;32m    490\u001b[0m )\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;66;03m# todo check if we need this when using cur_rollout_batch\u001b[39;00m\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;66;03m# if len(cur_rollout_batch) != len(ready_env_ids):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    500\u001b[0m \n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# get the next action\u001b[39;00m\n\u001b[1;32m    502\u001b[0m     (\n\u001b[1;32m    503\u001b[0m         act_RA,\n\u001b[1;32m    504\u001b[0m         act_normalized_RA,\n\u001b[1;32m    505\u001b[0m         policy_R,\n\u001b[1;32m    506\u001b[0m         hidden_state_RH,\n\u001b[0;32m--> 507\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_action_policy_hidden\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mready_env_ids_R\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mready_env_ids_R\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_obs_RO\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_obs_RO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_info_R\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_info_R\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_hidden_state_RH\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_hidden_state_RH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m     obs_next_RO, rew_R, terminated_R, truncated_R, info_R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(\n\u001b[1;32m    516\u001b[0m         act_normalized_RA,\n\u001b[1;32m    517\u001b[0m         ready_env_ids_R,\n\u001b[1;32m    518\u001b[0m     )\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(info_R, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# type: ignore[unreachable]\u001b[39;00m\n\u001b[1;32m    520\u001b[0m         \u001b[38;5;66;03m# This can happen if the env is an envpool env. Then the info returned by step is a dict\u001b[39;00m\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/tianshou/data/collector.py:419\u001b[0m, in \u001b[0;36mCollector._compute_action_policy_hidden\u001b[0;34m(self, random, ready_env_ids_R, last_obs_RO, last_info_R, last_hidden_state_RH)\u001b[0m\n\u001b[1;32m    416\u001b[0m info_batch \u001b[38;5;241m=\u001b[39m _HACKY_create_info_batch(last_info_R)\n\u001b[1;32m    417\u001b[0m obs_batch_R \u001b[38;5;241m=\u001b[39m cast(ObsBatchProtocol, Batch(obs\u001b[38;5;241m=\u001b[39mlast_obs_RO, info\u001b[38;5;241m=\u001b[39minfo_batch))\n\u001b[0;32m--> 419\u001b[0m act_batch_RA \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobs_batch_R\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlast_hidden_state_RH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m act_RA \u001b[38;5;241m=\u001b[39m to_numpy(act_batch_RA\u001b[38;5;241m.\u001b[39mact)\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_noise:\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/tianshou/policy/modelfree/pg.py:193\u001b[0m, in \u001b[0;36mPGPolicy.forward\u001b[0;34m(self, batch, state, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute action over the given batch data by applying the actor.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03mWill sample from the dist_fn, if appropriate.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    more detailed explanation.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# TODO - ALGO: marked for algorithm refactoring\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m action_dist_input_BD, hidden_BH \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# in the case that self.action_type == \"discrete\", the dist should always be Categorical, and D=A\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# therefore action_dist_input_BD is equivalent to logits_BA\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# If discrete, dist_fn will typically map loc, scale to a distribution (usually a Gaussian)\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# the action_dist_input_BD in that case is a tuple of loc_B, scale_B and needs to be unpacked\u001b[39;00m\n\u001b[1;32m    198\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist_fn(action_dist_input_BD)\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/alan/networks/actor_critic.py:21\u001b[0m, in \u001b[0;36mSimpleNetHackActor.forward\u001b[0;34m(self, batch_obs, state, info)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_obs, state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, info\u001b[38;5;241m=\u001b[39m{}):\n\u001b[0;32m---> 21\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits, state\n",
      "File \u001b[0;32m~/alan/networks/observation_net.py:137\u001b[0m, in \u001b[0;36mNetHackObsNet.forward\u001b[0;34m(self, env_out_batch)\u001b[0m\n\u001b[1;32m    135\u001b[0m crop_emb \u001b[38;5;241m=\u001b[39m crop_emb\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# -- TODO: slow?\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# -- [B x W' x H' x K]\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m crop_rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_crop_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrop_emb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# -- [B x K']\u001b[39;00m\n\u001b[1;32m    139\u001b[0m crop_rep \u001b[38;5;241m=\u001b[39m crop_rep\u001b[38;5;241m.\u001b[39mview(B, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/alan/lib/python3.12/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch_stats in trainer:\n",
    "    # TODO a more informative print, plots, logging, etc.\n",
    "    print(epoch_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
